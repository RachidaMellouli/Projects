{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RachidaMellouli/Projects/blob/main/dataAugmentation_project3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLQtXSIsDCbe",
        "outputId": "49818a20-7e90-477f-9606-8d00518612b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly import tools\n",
        "from scipy.stats import mannwhitneyu\n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.models import Sequential, Model,load_model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n",
        "from keras.preprocessing import image\n",
        "from keras.initializers import glorot_uniform\n",
        "y_train_test = []\n",
        "init_notebook_mode(connected=True) ## plotly init\n",
        "seed = 123\n",
        "random.seed = seed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VdZHF11aEKkn",
        "outputId": "d6363565-03f7-424a-8eb0-948deeaaa9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filenames_list_normal = os.listdir('./drive/MyDrive/projet2/normal/') ## list of file names in the directory\n",
        "filenames_list_grade1 = os.listdir('./drive/MyDrive/projet2/grade1/')\n",
        "filenames_list_grade2 = os.listdir('./drive/MyDrive/projet2/grade2/')\n",
        "filenames_list_grade3 = os.listdir('./drive/MyDrive/projet2/grade3/')\n",
        "filenames_list_cancer = os.listdir('./drive/MyDrive/projet2/cancer/')\n",
        "dataSet = [] ## create an empty df that will hold data from each file\n",
        "y_train_test = []\n",
        "i=0"
      ],
      "metadata": {
        "id": "815DB-IBEOrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name in tqdm(filenames_list_normal):\n",
        "    temp_df = cv2.imread('./drive/MyDrive/projet2/normal/' + file_name) ## read from the file to df\n",
        "    dataSet.append(temp_df) ## add the file data to the main df\n",
        "    y_train_test.append([1,0,0,0,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_t3r8QyEUK9",
        "outputId": "1f74e307-675a-4915-897e-9bd78065b949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 242/242 [00:00<00:00, 370.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataSet[100].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZZqjWp64Jmn",
        "outputId": "912fa10c-0bdf-44e5-f6e4-9cab4568457d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for file_name in tqdm(filenames_list_grade1):\n",
        "    temp_df = cv2.imread('./drive/MyDrive/projet2/grade1/' + file_name) ## read from the file to df\n",
        "    dataSet.append(temp_df) ## add the file data to the main df\n",
        "    y_train_test.append([0,1,0,0,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voKSecPeFj5m",
        "outputId": "4822e1b6-ce10-43b6-83a0-4185433cdebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182/182 [00:00<00:00, 409.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataSet[300].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkRFolCZu6r6",
        "outputId": "f3d72410-8c76-44b9-c857-9fae3bdddcf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for file_name in tqdm(filenames_list_grade2):\n",
        "    temp_df = cv2.imread('./drive/MyDrive/projet2/grade2/' + file_name) ## read from the file to df\n",
        "    dataSet.append(temp_df) ## add the file data to the main df\n",
        "    y_train_test.append([0,0,1,0,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUFXiaIyFoOM",
        "outputId": "026920a6-c625-4146-9360-8eb1f6238123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 146/146 [00:00<00:00, 422.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for file_name in tqdm(filenames_list_grade3):\n",
        "    temp_df = cv2.imread('./drive/MyDrive/projet2/grade3/' + file_name) ## read from the file to df\n",
        "    dataSet.append(temp_df) ## add the file data to the main df\n",
        "    y_train_test.append([0,0,0,1,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEGjXf56FztP",
        "outputId": "ce982c3c-56d1-4fcc-b4ec-8e945c666df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 197/197 [00:00<00:00, 419.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for file_name in tqdm(filenames_list_cancer):\n",
        "    temp_df = cv2.imread('./drive/MyDrive/projet2/cancer/' + file_name) ## read from the file to df\n",
        "    dataSet.append(temp_df) ## add the file data to the main df\n",
        "    y_train_test.append([0,0,0,0,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehAcpCL1F6VC",
        "outputId": "3d7538f8-42bc-40db-f787-e5029233ebf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 149/149 [00:00<00:00, 363.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w8ICdjk1fTjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in3OdvpUG_9_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rcCIoiooerpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ede3_kbeHOjR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as pyplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf #is a library  that can be used to create deep learning models\n",
        "#it is an open source library for fast numerical computing\n",
        "from keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img\n",
        "#keras is a deep learning API(application program interface)for building and training models in tensorflow\n",
        "import cv2 #OpenCV-Python is a library of Python bindings designed to solve computer vision problems\n",
        "import os,shutil  #The OS module in python provides functions for interacting with the operating system\n",
        "                  #The shutil module offers a number of high-level operations on files and collections of files\n",
        "from os import listdir #listdir() returns a list containing the names of the entries in the directory given by path.\n",
        "from pathlib import Path # Pathlib is an object oriented interface to the filesystem \n",
        "                         #and provides a more intuitive method to interact with the filesystem\n",
        "import numpy as  np #NumPy is a Python library used for working with arrays. \n",
        "filenames_list_normal = os.listdir('./drive/MyDrive/projet2/normal/') ## list of file names in the directory\n",
        "filenames_list_grade1 = os.listdir('./drive/MyDrive/projet2/grade1/')\n",
        "filenames_list_grade2 = os.listdir('./drive/MyDrive/projet2/grade2/')\n",
        "filenames_list_grade3 = os.listdir('./drive/MyDrive/projet2/grade3/')\n",
        "filenames_list_cancer = os.listdir('./drive/MyDrive/projet2/cancer/')\n",
        "normal_augmented=os.listdir('./drive/MyDrive/projet2/normal_augmented')\n",
        "grade1_augmented=os.listdir('./drive/MyDrive/projet2/grade1_augmented')\n",
        "grade2_augmented=os.listdir('./drive/MyDrive/projet2/grade2_augmented')\n",
        "grade3_augmented=os.listdir('./drive/MyDrive/projet2/grade3_augmented')\n",
        "cancer_augmented=os.listdir('./drive/MyDrive/projet2/cancer_augmented')\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "                                rotation_range=10, \n",
        "                                  width_shift_range=0.1, \n",
        "                                  height_shift_range=0.1, \n",
        "                                  shear_range=0.1, \n",
        "                                  brightness_range=(0.3, 1.0),\n",
        "                                  horizontal_flip=True, \n",
        "                                  vertical_flip=True, \n",
        "                                  fill_mode='nearest')\n",
        "for file in filenames_list_normal:\n",
        "  img = cv2.imread('./drive/MyDrive/projet2/normal/'+file)  # this is a PIL image\n",
        "  x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "  x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "          # the .flow() command below generates batches of randomly transformed images\n",
        "          # and saves the results to the yes_augmented directory\n",
        "  i = 0\n",
        "  for batch in datagen.flow(x, batch_size=1,\n",
        "                                    save_to_dir='./drive/MyDrive/projet2/normal_augmented', save_prefix='aug', save_format='jpg'):\n",
        "            i += 1\n",
        "            if i > 4:\n",
        "                  break  \n",
        "for file in filenames_list_grade1:\n",
        "  img = cv2.imread('./drive/MyDrive/projet2/grade1/'+file)  # this is a PIL image\n",
        "  x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "  x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "          # the .flow() command below generates batches of randomly transformed images\n",
        "          # and saves the results to the yes_augmented directory\n",
        "  i = 0\n",
        "  for batch in datagen.flow(x, batch_size=1,\n",
        "                                    save_to_dir='./drive/MyDrive/projet2/grade1_augmented', save_prefix='aug', save_format='jpg'):\n",
        "            i += 1\n",
        "            if i > 5:\n",
        "                  break  \n",
        "for file in filenames_list_grade2:\n",
        "  img = cv2.imread('./drive/MyDrive/projet2/grade2/'+file)  # this is a PIL image\n",
        "  x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "  x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "          # the .flow() command below generates batches of randomly transformed images\n",
        "          # and saves the results to the yes_augmented directory\n",
        "  i = 0\n",
        "  for batch in datagen.flow(x, batch_size=1,\n",
        "                                    save_to_dir='./drive/MyDrive/projet2/grade2_augmented', save_prefix='aug', save_format='jpg'):\n",
        "            i += 1\n",
        "            if i > 6:\n",
        "                  break\n",
        "for file in filenames_list_grade3:\n",
        "  img = cv2.imread('./drive/MyDrive/projet2/grade3/'+file)  # this is a PIL image\n",
        "  x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "  x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "          # the .flow() command below generates batches of randomly transformed images\n",
        "          # and saves the results to the yes_augmented directory\n",
        "  i = 0\n",
        "  for batch in datagen.flow(x, batch_size=1,\n",
        "                                    save_to_dir='./drive/MyDrive/projet2/grade3_augmented', save_prefix='aug', save_format='jpg'):\n",
        "            i += 1\n",
        "            if i > 5:\n",
        "                  break    \n",
        "for file in filenames_list_cancer:\n",
        "  img = cv2.imread('./drive/MyDrive/projet2/cancer/'+file)  # this is a PIL image\n",
        "  x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "  x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "              # the .flow() command below generates batches of randomly transformed images\n",
        "              # and saves the results to the no_augmented directory\n",
        "  i = 0\n",
        "  for batch in datagen.flow(x, batch_size=1,\n",
        "                                        save_to_dir='./drive/MyDrive/projet2/cancer_augmented', save_prefix='aug', save_format='jpg'):\n",
        "                  i += 1\n",
        "                  if i > 6:\n",
        "                    break "
      ],
      "metadata": {
        "id": "PsJ2T4jAgILk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_test = np.array(y_train_test)\n",
        "dataSet = np.array(dataSet)"
      ],
      "metadata": {
        "id": "E3u9-aARJtGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3045e3ea-02f1-482b-de15-d522358ff233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train_test.shape)\n",
        "print(dataSet.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_pvQijxhG-r",
        "outputId": "98c1b61a-9bcf-44c3-8cf9-644aed2c9590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1956, 5)\n",
            "(1956,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataSet[1000].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "SSQX3fOvI3xT",
        "outputId": "85ab4757-1c1a-4cff-bb99-8aad4074c323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-4783e75ed42f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ]
}